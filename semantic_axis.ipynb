{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KeyedVectors.load(os.path.join(\"w2v\", \"model.model\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_food = []\n",
    "negative_food = []\n",
    "positive_service = []\n",
    "negative_service = []\n",
    "\n",
    "with open(os.path.join(\"seeds\", \"Food_words.txt\"), \"r\") as fd:\n",
    "    food_words = fd.read().split(\"\\n\")\n",
    "\n",
    "for word in food_words:\n",
    "    line = word.split()\n",
    "    if line[-1] == \"1\":\n",
    "        positive_food.append(model[line[1]])\n",
    "    else:\n",
    "        negative_food.append(model[line[1]]) \n",
    "\n",
    "with open(os.path.join(\"seeds\", \"Service_words.txt\"), \"r\") as fd:\n",
    "    food_words = fd.read().split(\"\\n\")\n",
    "\n",
    "for word in food_words:\n",
    "    line = word.split()\n",
    "    if line[-1] == \"1\":\n",
    "        positive_service.append(model[line[1]])\n",
    "    else:\n",
    "        negative_service.append(model[line[1]]) \n",
    "        \n",
    "center_pos_food = np.mean(positive_food, axis=0)\n",
    "center_neg_food = np.mean(negative_food, axis=0)\n",
    "center_pos_service = np.mean(positive_service, axis=0)\n",
    "center_neg_service = np.mean(negative_service, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n",
      "(300,)\n",
      "(300,)\n",
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(center_pos_food.shape)\n",
    "print(center_neg_food.shape)\n",
    "print(center_pos_service.shape)\n",
    "print(center_neg_service.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sem_axis_food = center_pos_food - center_neg_food\n",
    "sem_axis_service = center_pos_service - center_neg_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.210892215371132\n",
      "1.2458789944648743\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "print(cosine(model[\"вкусно\"], sem_axis_food))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeightedWord:\n",
    "    def __init__(self, word, cosine, pos):\n",
    "        self.word = word\n",
    "        self.cosine = cosine\n",
    "        self.pos = pos\n",
    "        \n",
    "    def __lt__(self, other):\n",
    "        return self.cosine < other.cosine\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return self.cosine == other.cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19034/19034 [18:30<00:00, 17.14it/s]\n"
     ]
    }
   ],
   "source": [
    "from conllu import parse\n",
    "from tqdm import tqdm\n",
    "\n",
    "weighted_food = []\n",
    "processed_tokens = []\n",
    "weighted_service = []\n",
    "\n",
    "allowed_tags = [\"VERB\", \"NOUN\", \"ADJ\"]\n",
    "\n",
    "for file in tqdm(os.listdir(\"parsed_train\")):\n",
    "    fd = open(os.path.join(\"parsed_train\", file), \"r\")\n",
    "    conllu_text = parse(fd.read())\n",
    "    for sentence in conllu_text:\n",
    "        for word in sentence:\n",
    "            if word[\"lemma\"] in processed_tokens:\n",
    "                continue\n",
    "            \n",
    "            if word[\"upostag\"] in allowed_tags:\n",
    "                weighted_food.append(WeightedWord(word[\"lemma\"], \n",
    "                                                 cosine(model[word[\"form\"]], sem_axis_food),\n",
    "                                                 word[\"upostag\"]\n",
    "                                                ))\n",
    "                weighted_service.append(WeightedWord(word[\"lemma\"], \n",
    "                                                    cosine(model[word[\"form\"]], sem_axis_service),\n",
    "                                                    word[\"upostag\"]))\n",
    "                processed_tokens.append(word[\"lemma\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_food = sorted(weighted_food)\n",
    "sorted_service = sorted(weighted_service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(\"word_lists\", \"semantic_axis_method\", \"food.csv\"), \"w\") as final_fd:\n",
    "    for word in sorted_food:\n",
    "        final_fd.write(word.word + \"\\t\" + str(word.cosine) + \"\\n\")\n",
    "        \n",
    "with open(os.path.join(\"word_lists\", \"semantic_axis_method\", \"service.csv\"), \"w\") as final_fd:\n",
    "    for word in sorted_service:\n",
    "        final_fd.write(word.word + \"\\t\" + str(word.cosine) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
